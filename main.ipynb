{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitted by: Canete and Ebenezer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (10 points) Use the Wikipedia python module and access any topic, as you will use that as your corpus, with a word limit of 1000 words. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs. High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\" Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology. == Goals == The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research. === Reasoning and problem-solving === Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics. Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem. === Knowledge representation === Knowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas. A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as objects, properties, categories, and relations between objects; situations, events, states, and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge. Among the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications. === Planning and decision-making === An \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility. In classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked. In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "# Set the topic you want to fetch\n",
    "topic = \"Artificial Intelligence\"\n",
    "\n",
    "# Fetch the full page content\n",
    "page = wikipedia.page(topic)\n",
    "content = page.content\n",
    "\n",
    "# Limit the content to 1000 words\n",
    "words = content.split()[:1000]\n",
    "limited_content = ' '.join(words)\n",
    "\n",
    "print(limited_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (60 points) Train 2 models: a Bigram and Trigram Language Model, use the shared code as reference for bigram modeling, and update it to support trigrams. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter\n",
    "from fractions import Fraction\n",
    "import string\n",
    "\n",
    "# Sample corpus (replace this with your actual Wikipedia corpus)\n",
    "corpus = \"\"\"Artificial intelligence is the simulation of human intelligence \n",
    "            in machines that are programmed to think like humans and mimic their actions.\n",
    "            Intelligence artificial systems learn from data and improve over time.\"\"\"\n",
    "\n",
    "# Function to normalize the corpus\n",
    "def normalize_corpus(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "# Normalize and tokenize the corpus\n",
    "normalized_corpus = normalize_corpus(corpus)\n",
    "tokens = word_tokenize(normalized_corpus)\n",
    "\n",
    "# Function to train an n-gram model\n",
    "def train_ngram_model(tokens, n):\n",
    "    # Generate n-grams\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "\n",
    "    # Count frequency of each n-gram\n",
    "    n_gram_freq = Counter(n_grams)\n",
    "\n",
    "    # Count frequency of each prefix (n-1 grams)\n",
    "    prefix_counts = defaultdict(int)\n",
    "    for gram in n_grams:\n",
    "        prefix = gram[:-1]  # All words except the last one\n",
    "        prefix_counts[prefix] += 1\n",
    "\n",
    "    # Compute probabilities using the formula: P(w_n | w_n-1, ..., w_1) = Count(ngram) / Count(prefix)\n",
    "    n_gram_prob = defaultdict(Fraction)\n",
    "    for gram, count in n_gram_freq.items():\n",
    "        prefix = gram[:-1]\n",
    "        n_gram_prob[gram] = Fraction(count, prefix_counts[prefix])  # P(w_n | w_n-1, ..., w_1)\n",
    "\n",
    "    return n_gram_prob\n",
    "\n",
    "# Train Bigram Model (n=2)\n",
    "bigram_model = train_ngram_model(tokens, 2)\n",
    "\n",
    "# Train Trigram Model (n=3)\n",
    "trigram_model = train_ngram_model(tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Model Probabilities:\n",
      "('artificial', 'intelligence'): 1/2 (0.5000)\n",
      "('intelligence', 'is'): 1/3 (0.3333)\n",
      "('is', 'the'): 1 (1.0000)\n",
      "('the', 'simulation'): 1 (1.0000)\n",
      "('simulation', 'of'): 1 (1.0000)\n",
      "('of', 'human'): 1 (1.0000)\n",
      "('human', 'intelligence'): 1 (1.0000)\n",
      "('intelligence', 'in'): 1/3 (0.3333)\n",
      "('in', 'machines'): 1 (1.0000)\n",
      "('machines', 'that'): 1 (1.0000)\n",
      "('that', 'are'): 1 (1.0000)\n",
      "('are', 'programmed'): 1 (1.0000)\n",
      "('programmed', 'to'): 1 (1.0000)\n",
      "('to', 'think'): 1 (1.0000)\n",
      "('think', 'like'): 1 (1.0000)\n",
      "('like', 'humans'): 1 (1.0000)\n",
      "('humans', 'and'): 1 (1.0000)\n",
      "('and', 'mimic'): 1/2 (0.5000)\n",
      "('mimic', 'their'): 1 (1.0000)\n",
      "('their', 'actions'): 1 (1.0000)\n",
      "('actions', 'intelligence'): 1 (1.0000)\n",
      "('intelligence', 'artificial'): 1/3 (0.3333)\n",
      "('artificial', 'systems'): 1/2 (0.5000)\n",
      "('systems', 'learn'): 1 (1.0000)\n",
      "('learn', 'from'): 1 (1.0000)\n",
      "('from', 'data'): 1 (1.0000)\n",
      "('data', 'and'): 1 (1.0000)\n",
      "('and', 'improve'): 1/2 (0.5000)\n",
      "('improve', 'over'): 1 (1.0000)\n",
      "('over', 'time'): 1 (1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Bigram Model Probabilities:\")\n",
    "for gram, prob in bigram_model.items():\n",
    "    print(f\"{gram}: {prob} ({float(prob):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trigram Model Probabilities:\n",
      "('artificial', 'intelligence', 'is'): 1 (1.0000)\n",
      "('intelligence', 'is', 'the'): 1 (1.0000)\n",
      "('is', 'the', 'simulation'): 1 (1.0000)\n",
      "('the', 'simulation', 'of'): 1 (1.0000)\n",
      "('simulation', 'of', 'human'): 1 (1.0000)\n",
      "('of', 'human', 'intelligence'): 1 (1.0000)\n",
      "('human', 'intelligence', 'in'): 1 (1.0000)\n",
      "('intelligence', 'in', 'machines'): 1 (1.0000)\n",
      "('in', 'machines', 'that'): 1 (1.0000)\n",
      "('machines', 'that', 'are'): 1 (1.0000)\n",
      "('that', 'are', 'programmed'): 1 (1.0000)\n",
      "('are', 'programmed', 'to'): 1 (1.0000)\n",
      "('programmed', 'to', 'think'): 1 (1.0000)\n",
      "('to', 'think', 'like'): 1 (1.0000)\n",
      "('think', 'like', 'humans'): 1 (1.0000)\n",
      "('like', 'humans', 'and'): 1 (1.0000)\n",
      "('humans', 'and', 'mimic'): 1 (1.0000)\n",
      "('and', 'mimic', 'their'): 1 (1.0000)\n",
      "('mimic', 'their', 'actions'): 1 (1.0000)\n",
      "('their', 'actions', 'intelligence'): 1 (1.0000)\n",
      "('actions', 'intelligence', 'artificial'): 1 (1.0000)\n",
      "('intelligence', 'artificial', 'systems'): 1 (1.0000)\n",
      "('artificial', 'systems', 'learn'): 1 (1.0000)\n",
      "('systems', 'learn', 'from'): 1 (1.0000)\n",
      "('learn', 'from', 'data'): 1 (1.0000)\n",
      "('from', 'data', 'and'): 1 (1.0000)\n",
      "('data', 'and', 'improve'): 1 (1.0000)\n",
      "('and', 'improve', 'over'): 1 (1.0000)\n",
      "('improve', 'over', 'time'): 1 (1.0000)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrigram Model Probabilities:\")\n",
    "for gram, prob in trigram_model.items():\n",
    "    print(f\"{gram}: {prob} ({float(prob):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (30 points) Using a test sentence “The quick brown fox jumps over the lazy dog near the bank of the river.” OR generate your own test sentence, create a function that will determine the perplexity score for each trained model. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigram model perplexity -> Test Sentence “” -> Score: \n",
    "\n",
    "#Trigram model perplexity -> Test Sentence “” -> Score:\n",
    "\n",
    "#hi "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
